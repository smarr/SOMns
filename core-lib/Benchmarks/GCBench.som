(* Ported GCBench from PyPy Project: https://bitbucket.org/pypy/pypy/src/02ea09544fc9/pypy/translator/goal/gcbench.py
  Original comment was:

# Ported from a Java benchmark whose history is :
#  This is adapted from a benchmark written by John Ellis and Pete Kovac
#  of Post Communications.
#  It was modified by Hans Boehm of Silicon Graphics.
# 
#       This is no substitute for real applications.  No actual application
#       is likely to behave in exactly this way.  However, this benchmark was
#       designed to be more representative of real applications than other
#       Java GC benchmarks of which we are aware.
#       It attempts to model those properties of allocation requests that
#       are important to current GC techniques.
#       It is designed to be used either to obtain a single overall performance
#       number, or to give a more detailed estimate of how collector
#       performance varies with object lifetimes.  It prints the time
#       required to allocate and collect balanced binary trees of various
#       sizes.  Smaller trees result in shorter object lifetimes.  Each cycle
#       allocates roughly the same amount of memory.
#       Two data structures are kept around during the entire process, so
#       that the measured performance is representative of applications
#       that maintain some live in-memory data.  One of these is a tree
#       containing many pointers.  The other is a large array containing
#       double precision floating point numbers.  Both should be of comparable
#       size.
#
#       The results are only really meaningful together with a specification
#       of how much memory was used.  It is possible to trade memory for
#       better time performance.  This benchmark should be run in a 32 MB
#       heap, though we don't currently know how to enforce that uniformly.
#
#       Unlike the original Ellis and Kovac benchmark, we do not attempt
#       measure pause times.  This facility should eventually be added back
#       in.  There are several reasons for omitting it for now.  The original
#       implementation depended on assumptions about the thread scheduler
#       that don't hold uniformly.  The results really measure both the
#       scheduler and GC.  Pause time measurements tend to not fit well with
#       current benchmark suites.  As far as we know, none of the current
#       commercial Java implementations seriously attempt to minimize GC pause
#       times.
#
#       Known deficiencies:
#               - No way to check on memory use
#               - No cyclic data structures
#               - No attempt to measure variation with object size
#               - Results are sensitive to locking cost, but we don't
#                 check for proper locking
*)
class GCBenchSuite usingPlatform: platform andHarness: harness = (
| private Benchmark       = harness Benchmark.
  private Array           = platform kernel Array.
|
)(
  class GCBench = (
    | kStretchTreeDepth kLongLivedTreeDepth kArraySize kMaxTreeDepth
      kMinTreeDepth cur_depth|
  )(
    public innerBenchmarkLoop: innerIterations = (
      | temp_tree long_lived_tree array depths cur_depth t_start t_finish |
      kStretchTreeDepth   := 9 * innerIterations.
      kLongLivedTreeDepth := 8 * innerIterations.
      kArraySize := 250000 * innerIterations.
      kMaxTreeDepth := 8   * innerIterations.
      kMinTreeDepth := 2   * innerIterations.
      
      (* Stretching memory with a binary tree of depth kStretchTreeDepth *)

      temp_tree := self make_tree: kStretchTreeDepth.
      temp_tree := nil.

      (* Creating a long-lived binary tree of depth kLongLivedTreeDepth *)
      long_lived_tree := Node create.
      self populate: kLongLivedTreeDepth tree: long_lived_tree.

      (* Creating a long-lived array of kArraySize  doubles *)
      array := Array new: kArraySize withAll: 0.0.
      1 to: kArraySize / 2 do: [:value | array at: value put: 1.0 // value].
      depths := Array new: ((kMaxTreeDepth - kMinTreeDepth)/ 2 + 1).
      cur_depth := kMinTreeDepth.
      depths doIndexes: [:value |
        depths at: value put: cur_depth.
        cur_depth := cur_depth + 2.
      ].
      self time_constructions: depths.

      long_lived_tree == nil
        ifTrue: [ self error: 'test failed' ].
      ^ true
    )

    make_tree: depth = (
      depth <= 0
        ifTrue:  [ ^ Node create ]
        ifFalse: [
          ^ (Node create: (self make_tree: (depth - 1))
                    with: (self make_tree: (depth - 1)))]
    )

    time_constructions: depths = (
      depths do: [:value | self time_construction: value].
    )

    time_construction: depth = ( | niters t_start t_finish temp_tree |
      niters := self num_iters: depth.
      (* Creating niters trees of depth depth *)

      0 to: niters - 1 do: [:i |
        temp_tree := Node create.
        self populate: depth tree: temp_tree.
        temp_tree := nil.
      ].
      
      0 to: niters - 1 do: [:i |
        temp_tree := self make_tree: depth.
        temp_tree := nil.
      ].
    )

    num_iters: i = (
      ^(2 * (self tree_size: kStretchTreeDepth) / (self tree_size: i)).
    )

    populate: depth tree: node = (
      depth <= 0 ifFalse: [
        node left: Node create.
        node right: Node create.
        self populate: depth - 1 tree: node left.
        self populate: depth - 1 tree: node right.
      ]
    )

    tree_size: i = ( |val|
      val := 2.
      i timesRepeat: [val := val * 2].
      ^ val - 1
    )
  )
  
  class Node create: l with: r = (
  | public left  ::= l.
    public right ::= r.|
  )() : (
    public create = (
      ^ self create: nil with: nil
    )
  )

  public newInstance = ( ^ GCBench new )
  public setupVerifiedRun: run = ( run innerIterations: 1 )
)

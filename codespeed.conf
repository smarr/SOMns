# Config file for ReBench
# Config format is YAML (see http://yaml.org/ for detailed spec)

# this run definition will be choosen if no parameters are given to rebench.py
standard_run: all
standard_data_file: 'codespeed.data'

reporting:
    # results can also be reported to a codespeed instance
    # see: https://github.com/tobami/codespeed
    csv_file: latest-runs.csv
    csv_locale: de_DE.UTF-8
    codespeed:
        url: http://som-speed.stefan-marr.de/result/add/json/

# settings and requirements for statistic evaluation
statistics:
    min_runs: 5
    max_runs: 10
    confidence_level: 0.90
    error_margin: 0.005
 
# settings for quick runs, useful for fast feedback during experiments
quick_runs:
    min_runs: 3
    max_runs: 10
    max_time: 60   # time in seconds

# definition of benchmark suites
benchmark_suites:
    macro-startup:
        performance_reader: LogPerformance
        command: " %(benchmark)s "
        #input_sizes:
        #    - benchmarking.image ReBenchHarness
        max_runtime: 200
        benchmarks:
            - 1

    macro-steady:
        performance_reader: LogPerformance
        command: " %(benchmark)s "
        #input_sizes:
        #    - benchmarking.image ReBenchHarness
        max_runtime: 200
        benchmarks:
            - 1

    micro-startup-100:
        performance_reader: LogPerformance
        command: "~/.local/SOM/Examples/Benchmarks/BenchmarkHarness.som %(benchmark)s "
        max_runtime: 200
        benchmarks:
            - Fibonacci:
                extra_args: "1 0 300"
                codespeed_name: "Fibonacci 100x [>"
            - Dispatch:
                extra_args: "1 0 2000"
                codespeed_name: "Dispatch 100x [>"
            - Bounce:
                extra_args: "1 0 200"
                codespeed_name: "Bounce 100x [>"
            - Loop:
                extra_args: "1 0 1000"
                codespeed_name: "Loop 100x [>"
            - Permute:
                extra_args: "1 0 300"
                codespeed_name: "Permute 100x [>"
            - Queens:
                extra_args: "1 0 200"
                codespeed_name: "Queens 100x [>"
            - List:
                extra_args: "1 0 200"
                codespeed_name: "List 100x [>"
            - Recurse:
                extra_args: "1 0 300"
                codespeed_name: "Recurse 100x [>"
            - Storage:
                extra_args: "1 0 200"
                codespeed_name: "Storage 100x [>"
            - Sieve:
                extra_args: "1 0 500"
                codespeed_name: "Sieve 100x [>"
            - BubbleSort:
                extra_args: "1 0 300"
                codespeed_name: "BubbleSort 100x [>"
            - QuickSort:
                extra_args: "1 0 300"
                codespeed_name: "QuickSort 100x [>"
            - Sum:
                extra_args: "1 0 1000"
                codespeed_name: "Sum 100x [>"
            - Towers:
                extra_args: "1 0 200"
                codespeed_name: "Towers 100x [>"
            - TreeSort:
                extra_args: "1 0 100"
                codespeed_name: "TreeSort 100x [>"
            - IntegerLoop:
                extra_args: "1 0 800"
                codespeed_name: "IntegerLoop 100x [>"
            - FieldLoop:
                extra_args: "1 0 300"
                codespeed_name: "FieldLoop 100x [>"

    micro-startup:
        performance_reader: LogPerformance
        command: "~/.local/SOM/Examples/Benchmarks/BenchmarkHarness.som %(benchmark)s "
        max_runtime: 200
        benchmarks:
            - Fibonacci:
                extra_args: "1 0 3"
                codespeed_name: "Fibonacci [>"
            - Dispatch:
                extra_args: "1 0 20"
                codespeed_name: "Dispatch [>"
            - Bounce:
                extra_args: "1 0 2"
                codespeed_name: "Bounce [>"
            - Loop:
                extra_args: "1 0 10"
                codespeed_name: "Loop [>"
            - Permute:
                extra_args: "1 0 3"
                codespeed_name: "Permute [>"
            - Queens:
                extra_args: "1 0 2"
                codespeed_name: "Queens [>"
            - List:
                extra_args: "1 0 2"
                codespeed_name: "List [>"
            - Recurse:
                extra_args: "1 0 3"
                codespeed_name: "Recurse [>"
            - Storage:
                extra_args: "1 0 2"
                codespeed_name: "Storage [>"
            - Sieve:
                extra_args: "1 0 5"
                codespeed_name: "Sieve [>"
            - BubbleSort:
                extra_args: "1 0 3"
                codespeed_name: "BubbleSort [>"
            - QuickSort:
                extra_args: "1 0 3"
                codespeed_name: "QuickSort [>"
            - Sum:
                extra_args: "1 0 10"
                codespeed_name: "Sum [>"
            - Towers:
                extra_args: "1 0 2"
                codespeed_name: "Towers [>"
            - TreeSort:
                extra_args: "1 0 1"
                codespeed_name: "TreeSort [>"
            - IntegerLoop:
                extra_args: "1 0 8"
                codespeed_name: "IntegerLoop [>"
            - FieldLoop:
                extra_args: "1 0 3"
                codespeed_name: "FieldLoop [>"

    micro-steady-100:
        performance_reader: LogPerformance
        command: "~/.local/SOM/Examples/Benchmarks/BenchmarkHarness.som %(benchmark)s "
        #input_sizes:
        #    - benchmarking.image ReBenchHarness
        max_runtime: 200
        benchmarks:
            - Fibonacci:
                extra_args: "1 2 300"
                codespeed_name: "Fibonacci 100x >]"
            - Dispatch:
                extra_args: "1 2 2000"
                codespeed_name: "Dispatch 100x >]"
            - Bounce:
                extra_args: "1 2 200"
                codespeed_name: "Bounce 100x >]"
            - Loop:
                extra_args: "1 2 1000"
                codespeed_name: "Loop 100x >]"
            - Permute:
                extra_args: "1 2 300"
                codespeed_name: "Permute 100x >]"
            - Queens:
                extra_args: "1 2 200"
                codespeed_name: "Queens 100x >]"
            - List:
                extra_args: "1 2 200"
                codespeed_name: "List 100x >]"
            - Recurse:
                extra_args: "1 2 300"
                codespeed_name: "Recurse 100x >]"
            - Storage:
                extra_args: "1 2 200"
                codespeed_name: "Storage 100x >]"
            - Sieve:
                extra_args: "1 2 500"
                codespeed_name: "Sieve 100x >]"
            - BubbleSort:
                extra_args: "1 2 300"
                codespeed_name: "BubbleSort 100x >]"
            - QuickSort:
                extra_args: "1 2 300"
                codespeed_name: "QuickSort 100x >]"
            - Sum:
                extra_args: "1 2 1000"
                codespeed_name: "Sum 100x >]"
            - Towers:
                extra_args: "1 2 200"
                codespeed_name: "Towers 100x >]"
            - TreeSort:
                extra_args: "1 2 100"
                codespeed_name: "TreeSort 100x >]"
            - IntegerLoop:
                extra_args: "1 2 800"
                codespeed_name: "IntegerLoop 100x >]"
            - FieldLoop:
                extra_args: "1 2 300"
                codespeed_name: "FieldLoop 100x >]"
    micro-steady:
        performance_reader: LogPerformance
        command: "~/.local/SOM/Examples/Benchmarks/BenchmarkHarness.som %(benchmark)s "
        #input_sizes:
        #    - benchmarking.image ReBenchHarness
        max_runtime: 200
        benchmarks:
            - Fibonacci:
                extra_args: "1 2 3"
                codespeed_name: "Fibonacci >]"
            - Dispatch:
                extra_args: "1 2 20"
                codespeed_name: "Dispatch >]"
            - Bounce:
                extra_args: "1 2 2"
                codespeed_name: "Bounce >]"
            - Loop:
                extra_args: "1 2 10"
                codespeed_name: "Loop >]"
            - Permute:
                extra_args: "1 2 3"
                codespeed_name: "Permute >]"
            - Queens:
                extra_args: "1 2 2"
                codespeed_name: "Queens >]"
            - List:
                extra_args: "1 2 2"
                codespeed_name: "List >]"
            - Recurse:
                extra_args: "1 2 3"
                codespeed_name: "Recurse >]"
            - Storage:
                extra_args: "1 2 2"
                codespeed_name: "Storage >]"
            - Sieve:
                extra_args: "1 2 5"
                codespeed_name: "Sieve >]"
            - BubbleSort:
                extra_args: "1 2 3"
                codespeed_name: "BubbleSort >]"
            - QuickSort:
                extra_args: "1 2 3"
                codespeed_name: "QuickSort >]"
            - Sum:
                extra_args: "1 2 10"
                codespeed_name: "Sum >]"
            - Towers:
                extra_args: "1 2 2"
                codespeed_name: "Towers >]"
            - TreeSort:
                extra_args: "1 2 1"
                codespeed_name: "TreeSort >]"
            - IntegerLoop:
                extra_args: "1 2 8"
                codespeed_name: "IntegerLoop >]"
            - FieldLoop:
                extra_args: "1 2 3"
                codespeed_name: "FieldLoop >]"

# VMs have a name and are specified by a path and the binary to be executed
virtual_machines:
    SOM:
        path: .
        binary: som.sh
        args: "-cp Smalltalk "
    TruffleSOM-interpreter:
        path: TruffleSOM
        binary: som.sh
        args: ""
    TruffleSOM-graal:
        path: TruffleSOM
        binary: som.sh
        args: ""
    CSOM:
        path: .
        binary: CSOM
        args: "-cp Smalltalk "
    SOMpp:
        path: .
        binary: som.sh
        args: "-cp Smalltalk "
    PySOM:
        path: .
        binary: som.sh
        args: "-cp Smalltalk "
    RPySOM-interpreter:
        path: .
        binary: RPySOM-no-jit
        args: "-cp Smalltalk "
    RPySOM-jit:
        path: .
        binary: RPySOM-jit
        args: "-cp Smalltalk "
        
# define the benchmarks to be executed for a re-executable benchmark run
run_definitions:
    SOM:
        description: All benchmarks on SOM (Java, bytecode-based)
        actions: benchmark
        benchmark:
            - micro-startup-100
            - micro-steady-100
            - micro-startup
            - micro-steady
            #- macro-startup
            #- macro-steady
        executions: SOM
    TruffleSOM:
        description: All benchmarks on TruffleSOM (Java, AST Interpreter)
        actions: benchmark
        benchmark:
            - micro-startup
            - micro-steady
            - micro-startup-100
            - micro-steady-100
            #- macro-startup
            #- macro-steady
        executions:
            - TruffleSOM-interpreter
            - TruffleSOM-graal
    CSOM:
        description: All benchmarks on CSOM
        actions: benchmark
        benchmark:
            - micro-startup
            #- macro-startup
        executions:
            - CSOM
    SOMpp:
        description: All benchmarks on SOM++
        actions: benchmark
        benchmark:
            - micro-startup
            - micro-startup-100
            #- macro-startup
        executions:
            - SOMpp
    PySOM:
        description: All benchmarks on PySOM
        actions: benchmark
        benchmark:
            - micro-startup
            #- macro-startup
        executions:
            - PySOM
    RPySOM:
        description: All benchmarks on RPySOM
        actions: benchmark
        benchmark:
            - micro-startup
            - micro-steady
            - micro-startup-100
            - micro-steady-100
            #- macro-startup
            #- macro-steady
        executions:
            - RPySOM-interpreter
            - RPySOM-jit
